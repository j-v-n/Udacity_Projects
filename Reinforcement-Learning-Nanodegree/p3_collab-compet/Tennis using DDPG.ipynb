{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiagent Tennis - Competitive Solved Using DDPG\n",
    "### Udacity Project Submission by Jayanth Nair\n",
    "This notebook walks through the implementation of the vanilla DDPG algorithm to solve the UnityML Tennis Environment (2 agents competing against each other)\n",
    "\n",
    "This solution utilizes a common actor-critic network shared by both agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports to get environment up and running\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDPG Implementation Details\n",
    "\n",
    "#### Neural Network Architecture\n",
    "The DDPG network used in this notebook consists of common actor-critic networks.  The actor contains 3 fully connected layers and 1 output layer(24x128x64x2) with ReLU activation of the input and hidden layers.  The weights are initialized according to the DDPG paper\n",
    "\n",
    "The critic contains 3 fully connected layers and 1 output layer (24x128x64x1) with ReLU activation of input and hidden layers.\n",
    "\n",
    "The common actor-critic network utilizes an experience replay buffer where observations from both competing agents are stored\n",
    "\n",
    "#### Hyper-parameters\n",
    "\n",
    "|Hyper-parameter |Value |\n",
    "|:-------------- |:---- |\n",
    "|Replay Buffer Size | 1000000 |\n",
    "|Batch Size | 512 |\n",
    "|Discount Factor | 0.99 |\n",
    "|Learning Rate-Actor | 0.0001 |\n",
    "|Learning Rate-Critic | 0.0001 |\n",
    "|L2 Weight Decay | 0 |\n",
    "|Update Network Every _ Steps | 1|\n",
    "|Learn For _ Times | 1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%aimport ddpg_multiagent \n",
    "from ddpg_multiagent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents=states.shape[0] # number of agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing agent\n",
    "agent = Agent(state_size=state_size,action_size=action_size,random_seed=0,n_agents=n_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg_multiagent(n_agents, n_episodes=10000, max_t=1000, print_every=100):\n",
    "    '''\n",
    "    Function which runs the training process \n",
    "\n",
    "    Arguments:\n",
    "     n_agents (int) : Number of agents\n",
    "     n_episodes (int): Max number of episodes to run training\n",
    "     max_t (int): Max time steps in each episode\n",
    "     print_every (int): Printing summarized results every x episodes\n",
    " \n",
    "    Returns :\n",
    "     scores (list): List of averaged scores over all agents for each episode \n",
    "\n",
    "\n",
    "    '''\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    best_score = 0.\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        agent_scores = np.zeros(n_agents)\n",
    "        for t in range(max_t):\n",
    "            actions = [agent.act(states[agent_id], agent_id) for agent_id in range(n_agents)]\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            for agent_id in range(n_agents):\n",
    "                agent_scores[agent_id] += rewards[agent_id]\n",
    "                agent.step(states[agent_id], actions[agent_id], rewards[agent_id], \n",
    "                           next_states[agent_id], dones[agent_id], agent_id)\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        score = np.max(agent_scores)\n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        print('\\rEpisode # - {0},\\tAverage Score - {1},\\tAverage Score over 100 Episodes-{2}'.format(i_episode, round(score,2), round(np.mean(scores_deque),2)),end=\" \")\n",
    "        if score > best_score:\n",
    "            print('\\rScore of {0} better than previous best score of {1} - Saving weights!'.format(round(score,1),round(best_score,1)))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            best_score = score\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode # - {0},\\tAverage Score - {1},\\tAverage Score over 100 Episodes-{2}'.format(i_episode, round(score,1), round(np.mean(scores_deque),1)))\n",
    "        if score > 0.5 and np.mean(scores_deque) > 0.5:\n",
    "            print('\\rReacher environment with {0} agents solved in {1} episodes!'.format(n_agents,i_episode))\n",
    "            break\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jynth\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of 0.1 better than previous best score of 0.0 - Saving weights!0.01 \n",
      "Episode # - 16,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.01 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\udacity_reinforcement_learning\\Udacity Projects\\Reinforcement-Learning-Nanodegree\\p3_collab-compet\\ddpg_multiagent.py:118: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(self.critic_local.parameters(), 1) #clipping gradients as per tips from Udacity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode # - 100,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.01 \n",
      "Episode # - 200,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.0   \n",
      "Episode # - 300,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.0  \n",
      "Episode # - 400,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.0  \n",
      "Episode # - 500,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.0 \n",
      "Episode # - 600,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.0 \n",
      "Episode # - 700,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.0 \n",
      "Episode # - 800,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.0 \n",
      "Episode # - 900,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.0 \n",
      "Episode # - 1000,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.0 \n",
      "Episode # - 1100,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.03  \n",
      "Score of 0.2 better than previous best score of 0.1 - Saving weights!s-0.05  \n",
      "Episode # - 1200,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.16 \n",
      "Episode # - 1300,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.18  \n",
      "Score of 0.3 better than previous best score of 0.2 - Saving weights!s-0.09  \n",
      "Episode # - 1400,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.1  \n",
      "Episode # - 1500,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.19  \n",
      "Episode # - 1600,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.1   \n",
      "Episode # - 1700,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.1  \n",
      "Episode # - 1800,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.1  \n",
      "Score of 0.4 better than previous best score of 0.3 - Saving weights!es-0.1 \n",
      "Episode # - 1900,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.1 \n",
      "Episode # - 2000,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.11  \n",
      "Episode # - 2100,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.1   \n",
      "Episode # - 2200,\tAverage Score - 0.2,\tAverage Score over 100 Episodes-0.11  \n",
      "Score of 0.5 better than previous best score of 0.4 - Saving weights!s-0.11 \n",
      "Episode # - 2300,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.11 \n",
      "Episode # - 2400,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.11  \n",
      "Episode # - 2500,\tAverage Score - 0.0,\tAverage Score over 100 Episodes-0.12  \n",
      "Episode # - 2600,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.13  \n",
      "Score of 0.6 better than previous best score of 0.5 - Saving weights!es-0.13 \n",
      "Score of 0.6 better than previous best score of 0.6 - Saving weights!s-0.14 \n",
      "Episode # - 2700,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.26  \n",
      "Score of 0.9 better than previous best score of 0.6 - Saving weights!s-0.2   \n",
      "Score of 1.0 better than previous best score of 0.9 - Saving weights!s-0.2  \n",
      "Episode # - 2800,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.29 \n",
      "Score of 2.1 better than previous best score of 1.0 - Saving weights!s-0.23  \n",
      "Episode # - 2900,\tAverage Score - 0.6,\tAverage Score over 100 Episodes-0.35  \n",
      "Episode # - 3000,\tAverage Score - 0.7,\tAverage Score over 100 Episodes-0.335 \n",
      "Episode # - 3100,\tAverage Score - 0.1,\tAverage Score over 100 Episodes-0.34  \n",
      "Episode # - 3200,\tAverage Score - 0.4,\tAverage Score over 100 Episodes-0.33  \n",
      "Episode # - 3300,\tAverage Score - 0.2,\tAverage Score over 100 Episodes-0.46  \n",
      "Episode # - 3400,\tAverage Score - 0.5,\tAverage Score over 100 Episodes-0.4   \n",
      "Episode # - 3500,\tAverage Score - 0.2,\tAverage Score over 100 Episodes-0.47  \n",
      "Score of 2.4 better than previous best score of 2.1 - Saving weights!s-0.39 \n",
      "Episode # - 3600,\tAverage Score - 0.2,\tAverage Score over 100 Episodes-0.45  \n",
      "Score of 2.6 better than previous best score of 2.4 - Saving weights!s-0.5   \n",
      "Reacher environment with 2 agents solved in 3636 episodes!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = ddpg_multiagent(n_agents)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
